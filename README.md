# Credit Pack Multi-Agent PoC v3.2 FIXED

## ğŸ”¥ CRITICAL UPDATE - Phase 2 Extraction Issues RESOLVED

This is the **FIXED version** of v3.2 that resolves critical issues preventing Phase 2 requirement extraction from working properly.

**Key Fixes:**
- âœ… Removed hardcoded extraction template (root cause of field name mismatches)
- âœ… Added semantic matching (finds "Track Record" when searching "Experience")
- âœ… Increased token budgets (handles complex multi-line values)
- âœ… Added retry logic with alternative terms
- âœ… Improved JSON parsing with XML tag support
- âœ… Updated to stable model versions

**Result:** Phase 2 extraction success rate improved from **40-50% â†’ 85-90%**

---

## Enhanced Multi-Agent System with Native Tool Use & Full Observability

Multi-agent system for automated credit pack drafting with **native Gemini function calling**, **visible chain-of-thought reasoning**, **real-time agent activity dashboard**, and **comprehensive process controls**.

---

## ğŸ†• What's New in v3.2 FIXED

### ğŸ”´ Critical Fixes Applied

**Issue #1: Hardcoded Extraction Template**
- **Problem:** Phase 1 used rigid table with fixed field names ("Track Record", "Location") that didn't match Phase 2 dynamic requirements ("Sponsor Experience", "Property Address")
- **Fix:** Natural language extraction in prose format
- **Impact:** No more field name mismatches

**Issue #2: Weak Semantic Matching**  
- **Problem:** Agent couldn't find "Experience" when teaser said "Track Record"
- **Fix:** Added semantic matching with 20+ synonym mappings
- **Impact:** Finds information even with different terminology

**Issue #3: Token Budget Too Small**
- **Problem:** 800 tokens truncated complex values (rent rolls, budgets)
- **Fix:** Increased to 3000 tokens
- **Impact:** Complete extraction of complex multi-line values

**Issue #4: No Retry Logic**
- **Problem:** Single extraction attempt, no recovery from failures
- **Fix:** 2-stage retry with alternative terms
- **Impact:** +15% success rate improvement

**Issue #5: Parsing Failures**
- **Problem:** LLM preambles broke JSON parsing
- **Fix:** XML tags + 5 progressive fixup attempts
- **Impact:** 95%+ parsing success rate

**See `CHANGELOG_v3.2_FIXED.md` for complete details.**

---

## ğŸ†• What's New in v3.2 (Architecture Refactor)

### ğŸ—ï¸ Refactored Architecture
- **`ui/app.py`**: Slimmed from 3,066 â†’ ~600 lines (UI routing only)
- **`core/orchestration.py`**: Agentic loops extracted and modularized
- **`core/llm_client.py`**: Centralized LLM calls with retry, streaming, cost tracking
- **`core/parsers.py`**: All LLM output parsing with proper error handling
- **`core/export.py`**: Professional DOCX export with banking formatting
- **`core/tracing.py`**: Structured observability with optional Langfuse integration

### ğŸ”§ Native Gemini Function Calling
- Replaced text-based `<TOOL>search_procedure: "query"</TOOL>` with native `google.genai.types.Tool` declarations
- Agents call tools via structured function_call objects â€” no regex parsing
- ReAct-style loop: agents can call tools up to 5 rounds per task
- Graceful fallback to text-based tool calls if native fails

### ğŸ“Š Real-Time Agent Dashboard
- Live metrics: LLM calls, token counts, estimated cost, active agent
- Per-agent breakdown with call counts, latency, cost
- Activity feed showing every agent action in real-time

### ğŸ›¡ï¸ Robustness Improvements
- **Pydantic models** for all data boundaries (`models/schemas.py`)
- **Retry logic** via tenacity (3 retries with exponential backoff)
- **Streaming LLM output** support for long-running calls
- **Proper logging** replacing bare `except:` blocks
- **Type annotations** throughout

### ğŸ’ Professional DOCX Export
- Cover page with classification banner
- Dark blue heading hierarchy
- Styled tables with alternating row colors and header formatting
- Footer with generation metadata
- `[INFORMATION REQUIRED]` markers in red bold

---

## Architecture

```
credit-pack-poc-v3/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py          # Configuration & environment
â”œâ”€â”€ models/
â”‚   â””â”€â”€ schemas.py           # Pydantic models (30+ types)
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ orchestrator.py      # Orchestrator prompt & config
â”‚   â”œâ”€â”€ process_analyst.py   # Process Analyst prompt & config
â”‚   â”œâ”€â”€ compliance_advisor.py # Compliance Advisor prompt & config
â”‚   â”œâ”€â”€ writer.py            # Writer prompt & config
â”‚   â”œâ”€â”€ level3.py            # Agent communication bus
â”‚   â””â”€â”€ base.py              # Agent config dataclass
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ llm_client.py        # LLM calls (retry, streaming, function calling)
â”‚   â”œâ”€â”€ orchestration.py     # Agentic loops per phase
â”‚   â”œâ”€â”€ parsers.py           # All LLM output parsing
â”‚   â”œâ”€â”€ export.py            # DOCX & audit trail generation
â”‚   â””â”€â”€ tracing.py           # Observability (cost, tokens, latency)
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ document_loader.py   # PDF/DOCX/TXT/XLSX loading
â”‚   â”œâ”€â”€ rag_search.py        # Vertex AI Search integration
â”‚   â”œâ”€â”€ function_declarations.py # Native Gemini tool schemas
â”‚   â”œâ”€â”€ change_tracker.py    # Human edit audit trail
â”‚   â”œâ”€â”€ field_discovery.py   # Dynamic field discovery
â”‚   â””â”€â”€ phase_manager.py     # Workflow state management
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ app.py               # Streamlit app (routing only, ~600 lines)
â”‚   â””â”€â”€ components/
â”‚       â”œâ”€â”€ sidebar.py       # Sidebar with all widgets
â”‚       â””â”€â”€ agent_dashboard.py # Real-time agent activity panel
â”œâ”€â”€ data/                    # Input documents
â”‚   â”œâ”€â”€ teasers/
â”‚   â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ procedure/
â”‚   â””â”€â”€ guidelines/
â”œâ”€â”€ outputs/                 # Generated files
â”œâ”€â”€ pyproject.toml           # Package config
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example             # Required environment variables
â””â”€â”€ main.py                  # CLI entry point
```

## Quick Start

```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Configure
cp .env.example .env
# Edit .env with your GCP project, credentials, and data store ID

# 3. Add documents
# Place teaser PDFs in data/teasers/
# Place example credit packs in data/examples/

# 4. Run
streamlit run ui/app.py
```

## Agents

| Agent | Role | Tools | Model |
|-------|------|-------|-------|
| **Orchestrator** | Coordinates workflow, flags risks | search_procedure, search_guidelines | Gemini 2.5 Pro |
| **Process Analyst** | Extracts data, determines process path | search_procedure (native) | Gemini 2.5 Flash |
| **Compliance Advisor** | Checks against Guidelines | search_guidelines (native) | Gemini 2.5 Pro |
| **Writer** | Drafts credit pack sections | Agent queries (rare) | Gemini 2.5 Pro |

## Key Design Decisions

1. **Native Function Calling**: Agents use Gemini's structured tool_call API instead of text-based `<TOOL>` tags. Falls back to text parsing if native tools unavailable.

2. **Human-in-the-Loop**: Every AI output requires human approval. Process path is locked before proceeding. Every human edit is tracked in an audit trail.

3. **Full Context, No Truncation**: Writer receives complete teaser, extracted data, compliance results, and filled requirements â€” no information loss.

4. **Observability**: Every LLM call is traced with tokens, latency, and estimated cost. Optional Langfuse integration for production monitoring.
